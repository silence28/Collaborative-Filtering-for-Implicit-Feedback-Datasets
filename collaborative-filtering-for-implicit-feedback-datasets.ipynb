{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering for Implicit Feedback Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article for more details: http://yifanhu.net/PUB/cf.pdf\n",
    "\n",
    "Facebook use this implementation: http://www.benfrederickson.com/fast-implicit-matrix-factorization/\n",
    "https://jessesw.com/Rec-System/\n",
    "\n",
    "\n",
    "I used the code from the following page: https://www.kaggle.com/wikhung/implicit-cf-tensorflow-implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the data:\n",
    "\n",
    "The code implemented for collaborative filtering for implicit feedback needs some kind of interaction between the user and the item. Types of implicit feedback include purchase history, browsing history, search patterns, or even mouse movements. For example, a user that purchased many books by the same author probably likes that author.\n",
    "\n",
    "The data used here is from MovieLens with 100.000 recommendations from 943 users who have rated 1682 movies (Items).\n",
    "In this example, the rating is considered as an interaction, so the interaction could be a fraction of the video that has been watched.  \n",
    "\n",
    "Here we pretend like the interaction is the number of times the user has clicked on the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User  Item  Click\n",
      "0   196   242      3\n",
      "1   186   302      3\n",
      "2    22   377      1\n",
      "3   244    51      2\n",
      "4   166   346      1\n"
     ]
    }
   ],
   "source": [
    "path = 'u.data' # data path\n",
    "df = pd.read_csv(path, sep='\\t', names=['User', 'Item', 'Click', 'Timestamp'], header=None)\n",
    "df = df.drop('Timestamp', axis=1) # Removing Timestamp\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort the df by User, Item, and Click"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The users are sorted according to the items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of movies watch by the users = 300000\n",
      "\n",
      "       User  Item  Click\n",
      "32236     1     1      5\n",
      "23171     1     2      3\n",
      "83307     1     3      4\n",
      "62631     1     4      3\n",
      "47638     1     5      3\n"
     ]
    }
   ],
   "source": [
    "df_Sorted = df.sort_values(['User', 'Item', 'Click'])\n",
    "print(\"Total number of movies watch by the users = {}\\n\".format(df_Sorted.size))\n",
    "print(df_Sorted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the duplicated records (If someone watched the same item twice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of clean_df = 300000\n",
      "\n",
      "       User  Item  Click\n",
      "32236     1     1      5\n",
      "23171     1     2      3\n",
      "83307     1     3      4\n",
      "62631     1     4      3\n",
      "47638     1     5      3\n"
     ]
    }
   ],
   "source": [
    "clean_df = df_Sorted.drop_duplicates(['User', 'Item'], keep = 'last')\n",
    "print(\"Size of clean_df = {}\\n\".format(clean_df.size))\n",
    "print(clean_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 943 users and 1682 items in the data\n"
     ]
    }
   ],
   "source": [
    "n_User = len(clean_df.User.unique())\n",
    "n_Item = len(clean_df.Item.unique())\n",
    "\n",
    "print('There are {0} users and {1} items in the data'.format(n_User, n_Item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we build a matrix of Users x Items, how many cells in the matrix will be filled?\n",
    "Fraction of cells which is filled (Sparsity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.30% of the user-item matrix is filled\n"
     ]
    }
   ],
   "source": [
    "sparsity = clean_df.shape[0] / float(n_User * n_Item)\n",
    "print('{:.2%} of the user-item matrix is filled'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Item preference matrix:\n",
    "He we make a matrix which tells us which movie has been seen by the user. If the movie is watched by a user: \n",
    "\n",
    "\\begin{equation}\n",
    "p_{ui} =    \\begin{cases}\n",
    "    1, & r_{ui} > 0.\\\\\n",
    "    0, & r_{ui} = 0.\n",
    "  \\end{cases}\n",
    "  \\end{equation}\n",
    " \n",
    "$r_{ui}$: user $u$ clicked(or other interaction) number of times on item $i$\n",
    "\n",
    "$p_{ui}$: user $u$ consumed item $i$ $(r_{ui} > 0)$, then we have an indication that $u$ likes $i$ $(p_{ui} = 1)$.\n",
    "On the other hand, if $u$ never consumed $i$, we believe no preference $(p_{ui} = 0)$. \n",
    "\n",
    "The preference matrix $p_{ui}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single user preference on each items: [[1. 1. 1. ... 0. 0. 0.]]\n",
      "Shape of the User_Item_pref matrix: (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "User_Item_pref = clean_df.copy()\n",
    "User_Item_pref['Click'][User_Item_pref['Click'] > 0] = 1  \n",
    "User_Item_pref = User_Item_pref.pivot(index='User', columns='Item', values='Click')\n",
    "User_Item_pref.fillna(0, inplace=True)\n",
    "User_Item_pref = User_Item_pref.values\n",
    "\n",
    "print(\"Single user preference on each items: {}\".format(User_Item_pref[0:1])) \n",
    "print(\"Shape of the User_Item_pref matrix: {}\".format(User_Item_pref.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Item interaction matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User_Item_interactions: matrix where we can see the number of clicks for each user $r_{ui}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single user clicks on each items: [[4. 0. 0. ... 0. 0. 0.]]\n",
      "Shape of the User_Item_interactions matrix: (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "User_Item_interactions = clean_df.pivot(index='User', columns='Item', values='Click')\n",
    "User_Item_interactions.fillna(0, inplace=True)\n",
    "User_Item_interactions = User_Item_interactions.values\n",
    "print(\"Single user clicks on each items: {}\".format(User_Item_interactions[1:2])) \n",
    "print(\"Shape of the User_Item_interactions matrix: {}\".format(User_Item_interactions.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users viewed 20 or more items\n"
     ]
    }
   ],
   "source": [
    "k = 10 # Number of top k items we want to recommend for the user\n",
    "\n",
    "# View_counts counts the number of item purchased by each user:\n",
    "View_counts = np.apply_along_axis(np.bincount, 1, User_Item_pref.astype(int))\n",
    "\n",
    "# buyers_idx finds the users who seen 2*k movies/items:\n",
    "buyers_idx = np.where(View_counts[:, 1] >= k*2)[0] \n",
    "print('{0} users viewed {1} or more items'.format(len(buyers_idx), k*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected users for test set : [144 898 394 512  82 672 774 634 780 170 375 573 923 580 890 823 464 414\n",
      " 528 617 722 566 802 136 591 649 402 692 145 514 435 604  86 544 918  91\n",
      "  90 140 875 679 851 839 224 328 813 760 764 105 751 399 834 929 763 520\n",
      "  87 479 795 127 723 174 525 726 395 519 786 132 725  64 808 849 545 397\n",
      " 803 646 543 387 814 861 666 169 119 590 388  73 248 699  29  98 440 256\n",
      " 503 908 325 656 238]\n"
     ]
    }
   ],
   "source": [
    "test_frac = 0.2 \n",
    "test_users_idx = np.random.choice(buyers_idx,\n",
    "                                  size = int(np.ceil(len(buyers_idx) * test_frac)),\n",
    "                                  replace = False)\n",
    "\n",
    "val_users_idx = test_users_idx[:int(len(test_users_idx) / 2)]\n",
    "test_users_idx = test_users_idx[int(len(test_users_idx) / 2):]\n",
    "print(\"Randomly selected users for test set : {}\".format(test_users_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function used to mask the preferences data from training matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(interaction, dat, train, test, user_idx, k):\n",
    "    for user in user_idx:\n",
    "        purchases = np.where(dat[user, :] == 1)[0]\n",
    "        mask = np.random.choice(purchases, size = k, replace = False)\n",
    "        interaction[user, mask] = 0\n",
    "        train[user, mask] = 0\n",
    "        test[user, mask] = dat[user, mask]\n",
    "    return train, test, interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_matrix = np.zeros(shape = (n_User, n_Item))\n",
    "train_matrix = User_Item_pref.copy()\n",
    "test_matrix = zero_matrix.copy()\n",
    "val_matrix = zero_matrix.copy()\n",
    "\n",
    "# Mask the train matrix and create the validation and test matrices\n",
    "train_matrix, val_matrix, User_Item_interactions = data_process(User_Item_interactions,User_Item_pref, train_matrix, val_matrix, val_users_idx, k)\n",
    "train_matrix, test_matrix, User_Item_interactions = data_process(User_Item_interactions,User_Item_pref, train_matrix, test_matrix, test_users_idx, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "print(train_matrix.shape)\n",
    "print(val_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# let's take a look at what was actually accomplised\n",
    "# You can see the test matrix preferences are masked in the train matrix\n",
    "test_matrix[      test_users_idx[0]  , test_matrix[test_users_idx[0], :].nonzero()[0]   ]\n",
    "print(train_matrix[test_users_idx[0], test_matrix[test_users_idx[0], :].nonzero()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "Important: Several of the hyperparameters should be optimized by grid search!\n",
    "\n",
    "To understand the math read at the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # Create a new graphs\n",
    "\n",
    "pref = tf.placeholder(tf.float32, (n_User, n_Item))  # Here's the preference matrix\n",
    "interactions = tf.placeholder(tf.float32, (n_User, n_Item)) # Here viewed or not viewed matrix\n",
    "users_idx = tf.placeholder(tf.int32, (None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_features: Number of latent features to be extracted. (Hyperparameter)\n",
    "n_features = 10 \n",
    "\n",
    "# The X matrix represents the user latent preferences with a shape of user x latent features\n",
    "X = tf.Variable(tf.truncated_normal([n_User, n_features], mean = 0, stddev = 0.05))\n",
    "\n",
    "# The Y matrix represents the item latent features with a shape of item x latent features\n",
    "Y = tf.Variable(tf.truncated_normal([n_Item, n_features], mean = 0, stddev = 0.05))\n",
    "\n",
    "# Here's the initilization of the confidence parameter \n",
    "conf_alpha = tf.Variable(tf.random_uniform([1], 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a user bias vector n_User, n_Item\n",
    "user_bias = tf.Variable(tf.truncated_normal([n_User, 1], stddev = 0.2))\n",
    "\n",
    "# Concatenate the vector to the user matrix\n",
    "# Due to how matrix algebra works, we also need to add a column of ones to make sure\n",
    "# the resulting calculation will take into account the item biases.\n",
    "X_plus_bias = tf.concat([X, \n",
    "                         #tf.convert_to_tensor(user_bias, dtype = tf.float32),\n",
    "                         user_bias,\n",
    "                         tf.ones((n_User, 1), dtype = tf.float32)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the item bias vector\n",
    "item_bias = tf.Variable(tf.truncated_normal([n_Item, 1], stddev = 0.2))\n",
    "\n",
    "# Cocatenate the vector to the item matrix\n",
    "# Also, adds a column one for the same reason stated above.\n",
    "Y_plus_bias = tf.concat([Y, \n",
    "                         tf.ones((n_Item, 1), dtype = tf.float32),\n",
    "                         item_bias],\n",
    "                         axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we finally multiply the matrices together to estimate the predicted preferences\n",
    "pred_pref = tf.matmul(X_plus_bias, Y_plus_bias, transpose_b=True)\n",
    "\n",
    "# Construct the confidence matrix with the clicks and alpha paramter\n",
    "conf = 1 + conf_alpha * interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_sum(tf.multiply(conf, tf.square(tf.subtract(pref, pred_pref))))\n",
    "l2_sqr = tf.nn.l2_loss(X) + tf.nn.l2_loss(Y) + tf.nn.l2_loss(user_bias) + tf.nn.l2_loss(item_bias)\n",
    "\n",
    "lambda_c = 0.01\n",
    "loss = cost + lambda_c * l2_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "optimize = tf.train.AdagradOptimizer(learning_rate = lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function that helps to calculate the top k item that the user would prefer\n",
    "def top_k_precision(predicted, mat, k, user_idx):\n",
    "    \"\"\"The predicted is a (user x items) matrix is the probability for each \n",
    "    item.\"\"\"\n",
    "    precisions = []\n",
    "    \n",
    "    for user in user_idx:\n",
    "        rec = np.argsort(-predicted[user, :]) # The argsort sorts the recommendation\n",
    "                                            #for each user from high to low\n",
    "        top_k = rec[:k] # Getting the top k items\n",
    "        labels = mat[user, :].nonzero()[0]\n",
    "        precision = len(set(top_k) & set(labels)) / float(k) # Calculate the precisions from actual labels\n",
    "        precisions.append(precision)\n",
    "    return np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterations 0...', 'Training Loss 421353.38...', 'Train Precision 0.213...', 'Val Precision 0.029')\n",
      "('Iterations 10...', 'Training Loss 158854.97...', 'Train Precision 0.476...', 'Val Precision 0.079')\n",
      "('Iterations 20...', 'Training Loss 135906.41...', 'Train Precision 0.524...', 'Val Precision 0.091')\n",
      "('Iterations 30...', 'Training Loss 124850.24...', 'Train Precision 0.556...', 'Val Precision 0.091')\n",
      "('Iterations 40...', 'Training Loss 117339.80...', 'Train Precision 0.560...', 'Val Precision 0.090')\n",
      "('Iterations 50...', 'Training Loss 111481.17...', 'Train Precision 0.578...', 'Val Precision 0.090')\n",
      "('Iterations 60...', 'Training Loss 106546.64...', 'Train Precision 0.591...', 'Val Precision 0.089')\n",
      "Shape of the recommendation matrix : (943, 1682)\n",
      "\n",
      "The average test recommendation precision for all users = 12.32%\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "iterations = 70\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        sess.run(optimize, feed_dict = {pref: train_matrix,\n",
    "                                        interactions: User_Item_interactions})\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            mod_loss = sess.run(loss, feed_dict = {pref: train_matrix,\n",
    "                                                   interactions: User_Item_interactions})\n",
    "            mod_pred = pred_pref.eval()\n",
    "            train_precision = top_k_precision(mod_pred, train_matrix, k, val_users_idx)\n",
    "            val_precision = top_k_precision(mod_pred, val_matrix, k, val_users_idx)\n",
    "            print('Iterations {0}...'.format(i),\n",
    "                  'Training Loss {:.2f}...'.format(mod_loss),\n",
    "                  'Train Precision {:.3f}...'.format(train_precision),\n",
    "                  'Val Precision {:.3f}'.format(val_precision)\n",
    "                )\n",
    "\n",
    "    recommendation = pred_pref.eval() # This produce a matrix where the rows are the user and \n",
    "                                      #the columns are the expected recommendation for each movie\n",
    "    print(\"Shape of the recommendation matrix : {}\\n\".format(recommendation.shape))\n",
    "    test_precision = top_k_precision(recommendation, test_matrix, k, test_users_idx)\n",
    "    print('The average test recommendation precision for all users = {:.2f}%'.format(test_precision*100))\n",
    "    \n",
    "    #np.save(recommendation) # to save the recommendation matrix\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
